# Pool of credentials to use to crawl (each pool is specified by four properties ending with the same number: integer from 1 to 150)
# Credentials of the pool are used in a round robin way.
#    - for streaming crawlers it is needed to specify only one pool of credentials
#    - for rest crawler, more credential pools are specified, faster is the crawling process
# IMPORTANT: it is possible to specify up to 150 credentials
consumerKey_1=<your consumer key>
consumerSecret_1=<your consumer secret>
token_1=<your access token>
tokenSecret_1=<your access token secret>

consumerKey_2=<your consumer key>
consumerSecret_2=<your consumer secret>
token_2=<your access token>
tokenSecret_2=<your access token secret>

consumerKey_3=<your consumer key>
consumerSecret_3=<your consumer secret>
token_3=<your access token>
tokenSecret_3=<your access token secret>

consumerKey_4=<your consumer key>
consumerSecret_4=<your consumer secret>
token_4=<your access token>
tokenSecret_4=<your access token secret>

consumerKey_5=<your consumer key>
consumerSecret_5=<your consumer secret>
token_5=<your access token>
tokenSecret_5=<your access token secret>

consumerKey_6=<your consumer key>
consumerSecret_6=<your consumer secret>
token_6=<your access token>
tokenSecret_6=<your access token secret>

consumerKey_7=<your consumer key>
consumerSecret_7=<your consumer secret>
token_7=<your access token>
tokenSecret_7=<your access token secret>

consumerKey_8=<your consumer key>
consumerSecret_8=<your consumer secret>
token_8=<your access token>
tokenSecret_8=<your access token secret>

consumerKey_9=<your consumer key>
consumerSecret_9=<your consumer secret>
token_9=<your access token>
tokenSecret_9=<your access token secret>

consumerKey_10=<your consumer key>
consumerSecret_10=<your consumer secret>
token_10=<your access token>
tokenSecret_10=<your access token secret>

consumerKey_11=<your consumer key>
consumerSecret_11=<your consumer secret>
token_11=<your access token>
tokenSecret_11=<your access token secret>

consumerKey_12=<your consumer key>
consumerSecret_12=<your consumer secret>
token_12=<your access token>
tokenSecret_12=<your access token secret>

####################################################################################
# REST Cralwer of Twitter - by list of tweet IDs (tweetID)
# Class: TwitterRESTTweetIDlistCrawler
#   - Full path of the txt file to read tweet IDs from (one tweet ID per line)
tweetID.fullPathTweetIDs=../Datasets_Raw/UnannotatedTwitterID_training.csv
#   - Full path of the output folder to store crawling results 
tweetID.fullOutputDirPath=./saves
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetID.outputFormat=json


####################################################################################
# REST Cralwer of Twitter - by keyword(s)
# Class: TwitterRESTKeywordSearchCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetKeyword.fullPathKeywordList=./settings/keywords.txt
#   - Full path of the output folder to store crawling results 
tweetKeyword.fullOutputDirPath=./saves
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetKeyword.outputFormat=json
#   - If not empty, it is possible specify a language to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
# tweetKeyword.languageFilter=en,en-au,en-bz,en-ca,en-ie,en-jm,en-nz,en-za,en-tt,en-gb,en-us
# invalid
tweetKeyword.languageFilter=en

####################################################################################
# REST Cralwer of Twitter - by account timeline
# HOWTO: a new file with all the most recent tweets of the timelines of the users specified is created
# Class: TwitterRESTAccountTimelineCrawler
#   - Full path of the txt file to read account IDs from (line format: ACCOUNT NAME <TAB> ACCOUNT_ID_LONG)
#   Example: 
#   bbc	612473
#   arxiv	808633423300624384
tweetTimeline.fullPathAccountIDs=
#   - Full path of the output folder to store crawling results 
tweetTimeline.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetTimeline.outputFormat=json


####################################################################################
# TREAMING Cralwer of Twitter - retrieves all tweets matching some specific keywords / users and/or in some specific language.
# Class: TwitterSTREAMHashtagCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetSTREAMkeyword.fullPathKeywordList=
#   - Full path of the txt file to read terms from (line format: ACCOUNT NAME <TAB> ACCOUNT_ID_LONG)
#   Example: 
#   bbc	662708106
#   arxiv	1149879325
tweetSTREAMkeyword.fullPathUserList=
#   - Full path of the output folder to store crawling results 
tweetSTREAMkeyword.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetSTREAMkeyword.outputFormat=json
#   - If not empty, it is possible specify a comma separated language list to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetSTREAMkeyword.languageFilter=en
#   - If not empty, it is possible specify a number of seconds - max number of tweet to store per seconds per user or keyword 
tweetSTREAMkeyword.limitByOneTweetPerXsec=


####################################################################################
# STREAMING Cralwer of Twitter - retrieves all tweets generated inside a bounding box from a list and/or in some specific language.
# Class: TwitterSTREAMBboxCrawler
#   - Full path of the txt file to read bounding boxes from (one bounding box per line - line format: BOUNDING BOX NAME <TAB> BOUNDING BOX COORDINATES)
#   BOUNDING BOX COORDINATES should be always a comma-separated list of doubles in the following order: lngSW, latSW, lngNE, latNE
#   Example: 
#   BBOX_NAME1	2.1390724182128906,41.363024324309784,2.1680831909179688,41.40565583808169
#   BBAX_NAME2	2.06268310546875,41.3532318743157,2.1028518676757812,41.37732380781499
tweetSTREAMbbox.fullPathBoundingBoxes=
#   - Full path of the output folder to store crawling results 
tweetSTREAMbbox.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetSTREAMbbox.outputFormat=json
#   - If not empty, it is possible specify a comma separated language list to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetSTREAMbbox.languageFilter=en

